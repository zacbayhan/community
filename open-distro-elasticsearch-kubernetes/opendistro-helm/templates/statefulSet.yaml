{{- if eq .Values.metadata.role "data" }}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    component: elasticsearch
    role: {{ .Values.metadata.role }}
  name: {{ .Values.metadata.name }}-{{ .Values.metadata.role }}
  namespace: elasticsearch
spec:
  serviceName: {{ .Values.metadata.name }}-{{ .Values.metadata.role }}
  replicas: {{ .Values.resources.replicas }}
  selector:
    matchLabels:
      component: {{ .Values.metadata.name | quote }}
      role: {{ .Values.metadata.role }}
  template:
    metadata:
      labels:
        component: {{ .Values.metadata.name | quote }}
        role: data
      annotations:
        iam.amazonaws.com/role: {{ .Values.annotations.iam_arn }}
    spec:
      # Add toleration for not scheduling on dedicated node
      tolerations:
      - key: dedicated
        value: "true"
        effect: NoSchedule
      initContainers:
      - name: init-sysctl
        image: busybox:1.27.2
        command:
        - sysctl
        - -w
        - vm.max_map_count={{ .Values.resources.max_map_count }}
        securityContext:
          privileged: {{ .Values.security.deployments.privileged }}
      - name: fixmount
        command: [ 'sh', '-c', 'chown -R 1000:1000 /usr/share/elasticsearch/data' ]
        image: busybox
        volumeMounts:
          - mountPath: /usr/share/elasticsearch/data
            name: data
      # Weighted anti-affinity to disallow deploying client node to the same worker node as master node
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  component: {{ .Values.metadata.name | quote }}
                  role: data
        # Node Affinity to attract this Deployment's pods to a specific set of worker nodes
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: type # Replace this with corresponding worker node label's key
                operator: In
                values:
                - general # Replace this with corresponding worker node label's value
      serviceAccountName: {{ .Values.metadata.name | quote }}
      containers:
      - name: {{ .Values.metadata.name | quote }}
        env:
        - name: CLUSTER_NAME
          value: {{ .Values.metadata.clusterName }}
        {{- range $role, $enabled := .Values.roles }}
        - name: node.{{ $role }}
          value: "{{ $enabled }}"
        {{- end }}
        {{- range $key, $value := .Values.environmental_variables }}
        - name: {{ $key }}
          value: {{ $value | quote }}
        {{- end }}
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: DISCOVERY_SERVICE
          value: elasticsearch-discovery
        - name: KUBERNETES_NAMESPACE
          value: {{ .Values.metadata.namespace }}
        - name: NODE_DATA
          value: "true"
        - name: PROCESSORS
          value: {{ .Values.resources.limits.cpu }}
        - name: ES_JAVA_OPTS
          value: {{ .Values.resources.esJavaOpts }}
        # Official Image from Open Distro Team
        image: amazon/opendistro-for-elasticsearch:0.9.0
        imagePullPolicy: Always
        # only publish the transport port
        ports:
        - containerPort: {{ .Values.security.ports.transportPort }}
          name: transport
        resources:
          requests:
            memory: {{ .Values.resources.requests.memory }}
            cpu: {{ .Values.resources.requests.cpu }}
          limits:
            memory: {{ .Values.resources.limits.memory }}
            cpu: {{ .Values.resources.limits.cpu }}
        livenessProbe:
          tcpSocket:
            port: transport
          initialDelaySeconds: 60
          periodSeconds: 10
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: data
        - mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          name: config
          subPath: elasticsearch.yml
        - mountPath: /usr/share/elasticsearch/config/logging.yml
          name: config
          subPath: logging.yml
        - mountPath: /usr/share/elasticsearch/config/elk-crt.pem
          name: certs
          subPath: elk-crt.pem
          readOnly: true
        - mountPath: /usr/share/elasticsearch/config/elk-key.pem
          name: certs
          subPath: elk-key.pem
          readOnly: true
        - mountPath: /usr/share/elasticsearch/config/elk-root-ca.pem
          name: certs
          subPath: elk-root-ca.pem
          readOnly: true
        - mountPath: /usr/share/elasticsearch/config/admin-crt.pem
          name: certs
          subPath: admin-crt.pem
          readOnly: true
        - mountPath: /usr/share/elasticsearch/config/admin-key.pem
          name: certs
          subPath: admin-key.pem
          readOnly: true
        - mountPath: /usr/share/elasticsearch/config/admin-root-ca.pem
          name: certs
          subPath: admin-root-ca.pem
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: elasticsearch
      - name: certs
        secret:
          secretName: elasticsearch-tls-data
  volumeClaimTemplates:
  - metadata:
      name: {{ .Values.metadata.role | quote }}
    spec:
      accessModes: [ ReadWriteOnce ]
      storageClassName: elk-gp2
      resources:
        requests:
          storage: 2Ti
{{- end }}
